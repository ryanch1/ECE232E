{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:47.502564Z",
     "iopub.status.busy": "2020-08-08T06:26:47.501673Z",
     "iopub.status.idle": "2020-08-08T06:26:47.505486Z",
     "shell.execute_reply": "2020-08-08T06:26:47.504706Z"
    },
    "papermill": {
     "duration": 0.020733,
     "end_time": "2020-08-08T06:26:47.505686",
     "exception": false,
     "start_time": "2020-08-08T06:26:47.484953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:47.526969Z",
     "iopub.status.busy": "2020-08-08T06:26:47.526221Z",
     "iopub.status.idle": "2020-08-08T06:26:47.529080Z",
     "shell.execute_reply": "2020-08-08T06:26:47.528347Z"
    },
    "papermill": {
     "duration": 0.015265,
     "end_time": "2020-08-08T06:26:47.529201",
     "exception": false,
     "start_time": "2020-08-08T06:26:47.513936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:47.560516Z",
     "iopub.status.busy": "2020-08-08T06:26:47.559769Z",
     "iopub.status.idle": "2020-08-08T06:26:48.211145Z",
     "shell.execute_reply": "2020-08-08T06:26:48.210545Z"
    },
    "papermill": {
     "duration": 0.674103,
     "end_time": "2020-08-08T06:26:48.211269",
     "exception": false,
     "start_time": "2020-08-08T06:26:47.537166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward1 = np.zeros((10,10))\n",
    "reward1[9][9] = 1\n",
    "plt.pcolor(reward1)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap - Reward Function 1\")\n",
    "plt.show()\n",
    "\n",
    "reward2 = np.zeros((10,10))\n",
    "reward2[9][9]=10\n",
    "reward2[1][5]=reward2[1][6]= -100\n",
    "for i in [1,2,3,4,5,6]:\n",
    "    reward2[i][4]=-100\n",
    "reward2[2][6]= -100\n",
    "reward2[3][6]= -100\n",
    "reward2[3][7]= -100\n",
    "reward2[3][8]=-100\n",
    "for i in [4,5,6,7]:\n",
    "    reward2[i][8]=-100\n",
    "reward2[7][6]= -100 \n",
    "reward2[7][7]= -100\n",
    "reward2[8][6]= -100\n",
    "plt.pcolor(reward2)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar()\n",
    "plt.title(\"Heatmap - Reward Function 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010863,
     "end_time": "2020-08-08T06:26:48.232076",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.221213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 2&3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.259006Z",
     "iopub.status.busy": "2020-08-08T06:26:48.258253Z",
     "iopub.status.idle": "2020-08-08T06:26:48.290548Z",
     "shell.execute_reply": "2020-08-08T06:26:48.291170Z"
    },
    "papermill": {
     "duration": 0.049825,
     "end_time": "2020-08-08T06:26:48.291326",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.241501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dfb62d5d0fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiscount_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcur_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mUP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDOWN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reward_1' is not defined"
     ]
    }
   ],
   "source": [
    "state_space = np.tile(np.arange(0, 100, 10), (10, 1)) + np.arange(0, 10, 1).reshape((10, 1))\n",
    "discount_factor = 0.8\n",
    "random_probability = 0.1\n",
    "cur_reward = reward_1\n",
    "UP = 0\n",
    "DOWN = 1\n",
    "LEFT = 2\n",
    "RIGHT = 3\n",
    "all_actions = [UP, DOWN, LEFT, RIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.339161Z",
     "iopub.status.busy": "2020-08-08T06:26:48.330086Z",
     "iopub.status.idle": "2020-08-08T06:26:48.342007Z",
     "shell.execute_reply": "2020-08-08T06:26:48.341387Z"
    },
    "papermill": {
     "duration": 0.04086,
     "end_time": "2020-08-08T06:26:48.342129",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.301269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def state_to_coordinate(state, state_sets=state_space):\n",
    "    y, x = np.where(state_sets == state)\n",
    "    return (x[0], y[0])\n",
    "\n",
    "def coordinate_to_state(coordinate_x, coordinate_y, state_sets=state_space):\n",
    "    return state_sets[coordinate_y, coordinate_x]\n",
    "\n",
    "def get_valid_actions(state):\n",
    "    valid_actions = all_actions.copy()\n",
    "    x, y = state_to_coordinate(state)\n",
    "    if x == 0:\n",
    "        valid_actions.remove(LEFT)\n",
    "    elif x == 9:\n",
    "        valid_actions.remove(RIGHT)\n",
    "    if y == 0:\n",
    "        valid_actions.remove(UP)\n",
    "    elif y == 9:\n",
    "        valid_actions.remove(DOWN)\n",
    "    return valid_actions\n",
    "\n",
    "def get_next_states_probabilities(cur_state, cur_action):\n",
    "    cur_valid_actions = get_valid_actions(cur_state)\n",
    "    next_probabilities = [0] * 5 # Order UP, DOWN, LEFT, RIGHT, STAY\n",
    "    for action in cur_valid_actions: # w/4 for states inside the grid\n",
    "            next_probabilities[action] = random_probability / 4\n",
    "    \n",
    "    # Calculate the transition probabilities for an action\n",
    "    if (len(cur_valid_actions) == 4): # No boundary cases\n",
    "        next_probabilities[cur_action] += 1 - random_probability\n",
    "        next_probabilities[4] = 0 # Probability to state in the current state is 0\n",
    "    \n",
    "    else: # With probability to move out the grid\n",
    "        next_probabilities[4] = random_probability * (1 - len(cur_valid_actions) / 4)\n",
    "        if cur_action in cur_valid_actions:\n",
    "            next_probabilities[cur_action] += 1 - random_probability\n",
    "        else:\n",
    "            next_probabilities[4] += 1 - random_probability\n",
    "    \n",
    "    return next_probabilities\n",
    "\n",
    "def state_reward(state, reward_function):\n",
    "    x, y = state_to_coordinate(state)\n",
    "    return reward_function[y, x]\n",
    "\n",
    "def get_state_value_function(reward_function):\n",
    "    # Initialize\n",
    "    state_value_function = np.zeros((10, 10))\n",
    "    delta = 1 # Exit flag\n",
    "\n",
    "    while delta > 0.01:\n",
    "        delta = 0 \n",
    "        previous_state_value_function = state_value_function.copy()\n",
    "        # Loop over 100 states\n",
    "        for cur_state in range(100): \n",
    "            cur_x, cur_y = state_to_coordinate(cur_state)\n",
    "            previous_state_value = previous_state_value_function[cur_y, cur_x]\n",
    "            state_value_all_actions = [0] * 4\n",
    "\n",
    "            # Loop over all actions\n",
    "            for cur_action in all_actions:\n",
    "                transition_probabilities = get_next_states_probabilities(cur_state, cur_action) \n",
    "\n",
    "                # Sum over one action\n",
    "                for prob_idx in range(len(transition_probabilities)):\n",
    "                    prob = transition_probabilities[prob_idx]\n",
    "                    if (prob != 0): # Remove invalid case\n",
    "                        # Next state coordinate\n",
    "                        next_x = cur_x\n",
    "                        next_y = cur_y\n",
    "                        if prob_idx == 0: # Move up\n",
    "                            next_y -= 1\n",
    "                        elif prob_idx == 1: # Move down\n",
    "                            next_y += 1\n",
    "                        elif prob_idx == 2: # Move left\n",
    "                            next_x -= 1\n",
    "                        elif prob_idx == 3: # Move right\n",
    "                            next_x += 1\n",
    "                        else: # Stay in the state\n",
    "                            pass\n",
    "                        next_state = coordinate_to_state(next_x, next_y)\n",
    "                        state_value_all_actions[cur_action] += prob * (state_reward(next_state, reward_function) + \n",
    "                                                                       discount_factor * previous_state_value_function[next_y, next_x])\n",
    "\n",
    "            cur_state_value = max(state_value_all_actions)\n",
    "            state_value_function[cur_y, cur_x] = cur_state_value\n",
    "            delta = max(delta, abs(previous_state_value - cur_state_value)) \n",
    "    return state_value_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.381692Z",
     "iopub.status.busy": "2020-08-08T06:26:48.380589Z",
     "iopub.status.idle": "2020-08-08T06:26:48.385810Z",
     "shell.execute_reply": "2020-08-08T06:26:48.385163Z"
    },
    "papermill": {
     "duration": 0.033905,
     "end_time": "2020-08-08T06:26:48.385941",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.352036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_value_function_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74af606059b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplot_optimal_value_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value_function_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'state_value_function_1' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_optimal_value_map(table,title=\"\"):\n",
    "    plt.pcolor(table, cmap=ListedColormap(['white']), edgecolors='black')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    for y in range(table.shape[0]):\n",
    "        for x in range(table.shape[1]):\n",
    "            if(table[y, x] >= 10):\n",
    "                plt.text(x + 0.5, y + 0.5, '%.1f' % table[y, x],\n",
    "                horizontalalignment='center',\n",
    "                verticalalignment='center', fontsize=7.5)\n",
    "            else:\n",
    "                plt.text(x + 0.5, y + 0.5, '%.2f' % table[y, x],\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', fontsize=7.5)\n",
    "    plt.show()\n",
    "\n",
    "plot_optimal_value_map(state_value_function_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.427508Z",
     "iopub.status.busy": "2020-08-08T06:26:48.424760Z",
     "iopub.status.idle": "2020-08-08T06:26:48.433389Z",
     "shell.execute_reply": "2020-08-08T06:26:48.432658Z"
    },
    "papermill": {
     "duration": 0.037383,
     "end_time": "2020-08-08T06:26:48.433513",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.396130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-37aa489819e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstate_value_function_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_state_value_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimal value of states: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0a275847841e>\u001b[0m in \u001b[0;36mget_state_value_function\u001b[0;34m(reward_function)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Loop over all actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcur_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mtransition_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_states_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_actions' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_heat_map(heat_array, title):\n",
    "    min_value = np.min(heat_array)\n",
    "    max_value = np.max(heat_array)\n",
    "    plt.pcolor(heat_array)\n",
    "    plt.ylim(top=0, bottom=10)\n",
    "    plt.xlim(left=0, right=10)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "state_value_function_1 = get_state_value_function(reward1)\n",
    "print('Optimal value of states: ')\n",
    "pd.set_option('precision', 3)\n",
    "plot_heat_map(state_value_function_1, 's')# , 'Heat map of state values using reward function 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.009957,
     "end_time": "2020-08-08T06:26:48.453796",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.443839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.501495Z",
     "iopub.status.busy": "2020-08-08T06:26:48.500360Z",
     "iopub.status.idle": "2020-08-08T06:26:48.505018Z",
     "shell.execute_reply": "2020-08-08T06:26:48.504275Z"
    },
    "papermill": {
     "duration": 0.041199,
     "end_time": "2020-08-08T06:26:48.505139",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.463940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_value_function_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3a59607a4a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptimal_policy_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0moptimal_policy_function_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimal_policy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value_function_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimal policy using arrows: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint_optimal_policy_with_arrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_policy_function_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state_value_function_1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# policy function\n",
    "def print_optimal_policy_with_arrows(optimal_policy_function):\n",
    "    optimal_policy_symbols = np.chararray((10, 10), unicode=True)\n",
    "    #arrow_symbols = ['⇧','⇩','⇦','⇨']\n",
    "    arrow_symbols = ['↑','↓','←','→']\n",
    "    for i in range(4):\n",
    "        optimal_policy_symbols[optimal_policy_function == i] = arrow_symbols[i]\n",
    "    print(pd.DataFrame(optimal_policy_symbols))\n",
    "    \n",
    "\n",
    "def get_optimal_policy_function(state_value_function, reward_function):\n",
    "    # Initialize\n",
    "    optimal_policy_function = np.zeros((10, 10))\n",
    "\n",
    "    # Loop all states\n",
    "    for cur_state in range(100):  \n",
    "        cur_x, cur_y = state_to_coordinate(cur_state)\n",
    "        state_value_all_actions = [0] * 4\n",
    "\n",
    "        # Loop over all actions\n",
    "        for cur_action in all_actions:\n",
    "            transition_probabilities = get_next_states_probabilities(cur_state, cur_action) \n",
    "\n",
    "            # Sum over one action\n",
    "            for prob_idx in range(len(transition_probabilities)):\n",
    "                prob = transition_probabilities[prob_idx]\n",
    "                if (prob != 0): # Remove invalid case\n",
    "                    # Next state coordinate\n",
    "                    next_x = cur_x\n",
    "                    next_y = cur_y\n",
    "                    if prob_idx == 0: # Move up\n",
    "                        next_y -= 1\n",
    "                    elif prob_idx == 1: # Move down\n",
    "                        next_y += 1\n",
    "                    elif prob_idx == 2: # Move left\n",
    "                        next_x -= 1\n",
    "                    elif prob_idx == 3: # Move right\n",
    "                        next_x += 1\n",
    "                    else: # Stay in the state\n",
    "                        pass\n",
    "                    next_state = coordinate_to_state(next_x, next_y)\n",
    "                    state_value_all_actions[cur_action] += prob * (state_reward(next_state, reward_function) + discount_factor * state_value_function[next_y, next_x])\n",
    "        \n",
    "        #state_value_all_actions = np.around(state_value_all_actions, 3) # Round the value to 5 dicimal5\n",
    "        optimal_action = np.argmax(state_value_all_actions)\n",
    "        optimal_policy_function[cur_y, cur_x] = optimal_action\n",
    "        #print('State: ', cur_state)\n",
    "        #print(state_value_all_actions)\n",
    "    return optimal_policy_function.astype(int)\n",
    "\n",
    "optimal_policy_function_1 = get_optimal_policy_function(state_value_function_1, reward1)\n",
    "print('Optimal policy using arrows: ')\n",
    "print_optimal_policy_with_arrows(optimal_policy_function_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010199,
     "end_time": "2020-08-08T06:26:48.525937",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.515738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.562067Z",
     "iopub.status.busy": "2020-08-08T06:26:48.555030Z",
     "iopub.status.idle": "2020-08-08T06:26:48.570074Z",
     "shell.execute_reply": "2020-08-08T06:26:48.569320Z"
    },
    "papermill": {
     "duration": 0.033809,
     "end_time": "2020-08-08T06:26:48.570194",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.536385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d95d56190c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate_value_function_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_state_value_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimal value of states: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_optimal_value_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value_function_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0a275847841e>\u001b[0m in \u001b[0;36mget_state_value_function\u001b[0;34m(reward_function)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Loop over all actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcur_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mtransition_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_states_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_actions' is not defined"
     ]
    }
   ],
   "source": [
    "state_value_function_2 = get_state_value_function(reward2)\n",
    "print('Optimal value of states: ')\n",
    "pd.set_option('precision', 3)\n",
    "plot_optimal_value_map(state_value_function_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.009969,
     "end_time": "2020-08-08T06:26:48.590489",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.580520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.623321Z",
     "iopub.status.busy": "2020-08-08T06:26:48.622302Z",
     "iopub.status.idle": "2020-08-08T06:26:48.626974Z",
     "shell.execute_reply": "2020-08-08T06:26:48.626318Z"
    },
    "papermill": {
     "duration": 0.026182,
     "end_time": "2020-08-08T06:26:48.627100",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.600918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_value_function_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6a283efacaf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_heat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value_function_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# , 'Heat map of state values using reward function 1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'state_value_function_2' is not defined"
     ]
    }
   ],
   "source": [
    "plot_heat_map(state_value_function_2, 's')# , 'Heat map of state values using reward function 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010226,
     "end_time": "2020-08-08T06:26:48.648023",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.637797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T06:26:48.681463Z",
     "iopub.status.busy": "2020-08-08T06:26:48.679771Z",
     "iopub.status.idle": "2020-08-08T06:26:48.686265Z",
     "shell.execute_reply": "2020-08-08T06:26:48.686831Z"
    },
    "papermill": {
     "duration": 0.02823,
     "end_time": "2020-08-08T06:26:48.686987",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.658757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_value_function_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d0dec42923b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimal_policy_function_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimal_policy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_value_function_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimal policy using arrows: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint_optimal_policy_with_arrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_policy_function_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state_value_function_2' is not defined"
     ]
    }
   ],
   "source": [
    "optimal_policy_function_2 = get_optimal_policy_function(state_value_function_2, reward2)\n",
    "print('Optimal policy using arrows: ')\n",
    "print_optimal_policy_with_arrows(optimal_policy_function_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010367,
     "end_time": "2020-08-08T06:26:48.708091",
     "exception": false,
     "start_time": "2020-08-08T06:26:48.697724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 6.294368,
   "end_time": "2020-08-08T06:26:48.826118",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-08T06:26:42.531750",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
